{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> The D-ACO/GA Project <br>\n",
    "## <center> (Digital - Ant Colony Optimization/Genetic Algorithm)\n",
    "### <center> Classification with Spark\n",
    "#### <center> Dataset NBaIoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfomCy9dDbMk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importação de modulos Python\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.ml import feature\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas Graficas\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exibe gráficos na página (inline)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação e Avaliação - Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 15:13:49 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "       .appName(\"D-ACO/IDS_SPARK\")\\\n",
    "       .master(\"spark://192.168.1.20:7077\") \\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção e Apresentação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L0_1_mean</th>\n",
       "      <th>MI_dir_L0_1_variance</th>\n",
       "      <th>MI_dir_L0_01_weight</th>\n",
       "      <th>MI_dir_L0_01_mean</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L5_variance</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L3_mean</th>\n",
       "      <th>H_L3_variance</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L1_variance</th>\n",
       "      <th>H_L0_1_weight</th>\n",
       "      <th>H_L0_1_variance</th>\n",
       "      <th>HH_L5_weight</th>\n",
       "      <th>HH_L5_std</th>\n",
       "      <th>HH_L5_magnitude</th>\n",
       "      <th>HH_L5_covariance</th>\n",
       "      <th>HH_L5_pcc</th>\n",
       "      <th>HH_L3_weight</th>\n",
       "      <th>HH_L3_magnitude</th>\n",
       "      <th>HH_L3_covariance</th>\n",
       "      <th>HH_L3_pcc</th>\n",
       "      <th>HH_L1_magnitude</th>\n",
       "      <th>HH_L1_radius</th>\n",
       "      <th>HH_L0_1_weight</th>\n",
       "      <th>HH_L0_1_magnitude</th>\n",
       "      <th>HH_L0_01_mean</th>\n",
       "      <th>HH_L0_01_std</th>\n",
       "      <th>HH_L0_01_magnitude</th>\n",
       "      <th>HH_L0_01_radius</th>\n",
       "      <th>HH_jit_L5_mean</th>\n",
       "      <th>HH_jit_L5_variance</th>\n",
       "      <th>HH_jit_L3_mean</th>\n",
       "      <th>HH_jit_L1_variance</th>\n",
       "      <th>HH_jit_L0_1_weight</th>\n",
       "      <th>HH_jit_L0_1_mean</th>\n",
       "      <th>HH_jit_L0_01_mean</th>\n",
       "      <th>HpHp_L5_radius</th>\n",
       "      <th>HpHp_L5_covariance</th>\n",
       "      <th>HpHp_L5_pcc</th>\n",
       "      <th>HpHp_L3_magnitude</th>\n",
       "      <th>HpHp_L3_covariance</th>\n",
       "      <th>HpHp_L1_mean</th>\n",
       "      <th>HpHp_L1_std</th>\n",
       "      <th>HpHp_L1_covariance</th>\n",
       "      <th>HpHp_L0_1_std</th>\n",
       "      <th>HpHp_L0_1_radius</th>\n",
       "      <th>HpHp_L0_1_pcc</th>\n",
       "      <th>HpHp_L0_01_weight</th>\n",
       "      <th>HpHp_L0_01_std</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.140165</td>\n",
       "      <td>57395.127337</td>\n",
       "      <td>334.618741</td>\n",
       "      <td>63520.590911</td>\n",
       "      <td>15639.792358</td>\n",
       "      <td>335.620212</td>\n",
       "      <td>102.845561</td>\n",
       "      <td>5.059634e+04</td>\n",
       "      <td>136.140165</td>\n",
       "      <td>231.720797</td>\n",
       "      <td>57395.127337</td>\n",
       "      <td>257.292295</td>\n",
       "      <td>63686.236834</td>\n",
       "      <td>3115.625242</td>\n",
       "      <td>63520.590911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.507658e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507658e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.507658e+09</td>\n",
       "      <td>1.507658e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216.350414</td>\n",
       "      <td>45.873516</td>\n",
       "      <td>69.439350</td>\n",
       "      <td>43.127894</td>\n",
       "      <td>29217.179583</td>\n",
       "      <td>69.380435</td>\n",
       "      <td>131.083524</td>\n",
       "      <td>4.867558e+01</td>\n",
       "      <td>216.350414</td>\n",
       "      <td>68.768196</td>\n",
       "      <td>45.873516</td>\n",
       "      <td>667.176854</td>\n",
       "      <td>42.867384</td>\n",
       "      <td>6684.153422</td>\n",
       "      <td>43.127894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.507657e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507657e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.507657e+09</td>\n",
       "      <td>1.507657e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.584313</td>\n",
       "      <td>56327.616925</td>\n",
       "      <td>341.306889</td>\n",
       "      <td>59809.003237</td>\n",
       "      <td>33084.034136</td>\n",
       "      <td>341.878436</td>\n",
       "      <td>169.499177</td>\n",
       "      <td>5.236953e+04</td>\n",
       "      <td>240.584313</td>\n",
       "      <td>375.260774</td>\n",
       "      <td>56327.616925</td>\n",
       "      <td>485.329427</td>\n",
       "      <td>59074.194845</td>\n",
       "      <td>3802.324281</td>\n",
       "      <td>59809.003237</td>\n",
       "      <td>116.604833</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.513615</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>553.9992</td>\n",
       "      <td>3.949556e-01</td>\n",
       "      <td>2165.489329</td>\n",
       "      <td>553.854057</td>\n",
       "      <td>553.816894</td>\n",
       "      <td>9.508991e+00</td>\n",
       "      <td>553.816894</td>\n",
       "      <td>9.042092e+01</td>\n",
       "      <td>2.818989e-03</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>3.551617e-03</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>2165.489329</td>\n",
       "      <td>1.762503e-02</td>\n",
       "      <td>1.323913e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.055691</td>\n",
       "      <td>4.122127</td>\n",
       "      <td>60.115786</td>\n",
       "      <td>2.018709</td>\n",
       "      <td>19946.169232</td>\n",
       "      <td>60.098659</td>\n",
       "      <td>66.660728</td>\n",
       "      <td>3.097987e+00</td>\n",
       "      <td>90.055691</td>\n",
       "      <td>60.188445</td>\n",
       "      <td>4.122127</td>\n",
       "      <td>216.098300</td>\n",
       "      <td>3.770803</td>\n",
       "      <td>2011.407214</td>\n",
       "      <td>2.018709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.253320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.590500</td>\n",
       "      <td>29646.295000</td>\n",
       "      <td>143.852278</td>\n",
       "      <td>131.428446</td>\n",
       "      <td>1.062896</td>\n",
       "      <td>9.090000e-13</td>\n",
       "      <td>1.253320</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.305204</td>\n",
       "      <td>0.042093</td>\n",
       "      <td>32.569167</td>\n",
       "      <td>29646.295000</td>\n",
       "      <td>1.062896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.253313</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0000</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>13.453078</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>9.540000e-07</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>9.090000e-13</td>\n",
       "      <td>9.964400e-01</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>9.967851e-01</td>\n",
       "      <td>0.497766</td>\n",
       "      <td>13.453078</td>\n",
       "      <td>1.060831e+01</td>\n",
       "      <td>4.625443e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.993117</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MI_dir_L3_weight  MI_dir_L3_variance  MI_dir_L0_1_mean  MI_dir_L0_1_variance  MI_dir_L0_01_weight  MI_dir_L0_01_mean  H_L5_weight  H_L5_variance  H_L3_weight   H_L3_mean  H_L3_variance  H_L1_weight  H_L1_variance  H_L0_1_weight  H_L0_1_variance  HH_L5_weight  HH_L5_std  HH_L5_magnitude  HH_L5_covariance  HH_L5_pcc  HH_L3_weight  HH_L3_magnitude  HH_L3_covariance  HH_L3_pcc  HH_L1_magnitude  HH_L1_radius  HH_L0_1_weight  HH_L0_1_magnitude  HH_L0_01_mean  HH_L0_01_std  HH_L0_01_magnitude  HH_L0_01_radius  HH_jit_L5_mean  HH_jit_L5_variance  HH_jit_L3_mean  HH_jit_L1_variance  HH_jit_L0_1_weight  HH_jit_L0_1_mean  HH_jit_L0_01_mean  HpHp_L5_radius  HpHp_L5_covariance  HpHp_L5_pcc  HpHp_L3_magnitude  HpHp_L3_covariance  HpHp_L1_mean  HpHp_L1_std  HpHp_L1_covariance  HpHp_L0_1_std  HpHp_L0_1_radius  HpHp_L0_1_pcc  HpHp_L0_01_weight  HpHp_L0_01_std  label\n",
       "0        136.140165        57395.127337        334.618741          63520.590911         15639.792358         335.620212   102.845561   5.059634e+04   136.140165  231.720797   57395.127337   257.292295   63686.236834    3115.625242     63520.590911      1.000000   0.000000             60.0               0.0        0.0      1.000000             60.0               0.0        0.0          60.0000  0.000000e+00        1.000000          60.000000      60.000000  0.000000e+00           60.000000     0.000000e+00    1.507658e+09            0.000000    1.507658e+09            0.000000            1.000000      1.507658e+09       1.507658e+09             0.0                 0.0          0.0               60.0                 0.0          60.0          0.0                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "1        216.350414           45.873516         69.439350             43.127894         29217.179583          69.380435   131.083524   4.867558e+01   216.350414   68.768196      45.873516   667.176854      42.867384    6684.153422        43.127894      1.000000   0.000000             60.0               0.0        0.0      1.000000             60.0               0.0        0.0          60.0000  0.000000e+00        1.000000          60.000000      60.000000  0.000000e+00           60.000000     0.000000e+00    1.507657e+09            0.000000    1.507657e+09            0.000000            1.000000      1.507657e+09       1.507657e+09             0.0                 0.0          0.0               60.0                 0.0          60.0          0.0                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "2        240.584313        56327.616925        341.306889          59809.003237         33084.034136         341.878436   169.499177   5.236953e+04   240.584313  375.260774   56327.616925   485.329427   59074.194845    3802.324281     59809.003237    116.604833   0.000013            554.0               0.0        0.0    153.513615            554.0               0.0        0.0         553.9992  3.949556e-01     2165.489329         553.854057     553.816894  9.508991e+00          553.816894     9.042092e+01    2.818989e-03            0.000249    3.551617e-03            0.001044         2165.489329      1.762503e-02       1.323913e+04             0.0                 0.0          0.0              554.0                 0.0         554.0          0.0                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "3         90.055691            4.122127         60.115786              2.018709         19946.169232          60.098659    66.660728   3.097987e+00    90.055691   60.188445       4.122127   216.098300       3.770803    2011.407214         2.018709      1.000000   0.000000             60.0               0.0        0.0      1.000000             60.0               0.0        0.0          60.0000  0.000000e+00        1.000000          60.000000      60.000000  0.000000e+00           60.000000     0.000000e+00    1.507654e+09            0.000000    1.507654e+09            0.000000            1.000000      1.507654e+09       1.507654e+09             0.0                 0.0          0.0               60.0                 0.0          60.0          0.0                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "4          1.253320            0.000000        123.590500          29646.295000           143.852278         131.428446     1.062896   9.090000e-13     1.253320   74.000000       0.000000     2.305204       0.042093      32.569167     29646.295000      1.062896   0.000000             74.0               0.0        0.0      1.253313             74.0               0.0        0.0          74.0000  1.820000e-12       13.453078          74.000000      74.000000  9.540000e-07           74.000000     9.090000e-13    9.964400e-01            0.058909    9.967851e-01            0.497766           13.453078      1.060831e+01       4.625443e+01             0.0                 0.0          0.0               74.0                 0.0          74.0          0.0                 0.0       0.000001      1.820000e-12            0.0           1.993117        0.000001      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = ps.read_csv('../../../../../datasets/dacoga/nbaiot/bestsub/NBaIoT100Train_GA_2024_02_25_08_25_00_selected.csv')\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L0_1_mean</th>\n",
       "      <th>MI_dir_L0_1_variance</th>\n",
       "      <th>MI_dir_L0_01_weight</th>\n",
       "      <th>MI_dir_L0_01_mean</th>\n",
       "      <th>H_L5_weight</th>\n",
       "      <th>H_L5_variance</th>\n",
       "      <th>H_L3_weight</th>\n",
       "      <th>H_L3_mean</th>\n",
       "      <th>H_L3_variance</th>\n",
       "      <th>H_L1_weight</th>\n",
       "      <th>H_L1_variance</th>\n",
       "      <th>H_L0_1_weight</th>\n",
       "      <th>H_L0_1_variance</th>\n",
       "      <th>HH_L5_weight</th>\n",
       "      <th>HH_L5_std</th>\n",
       "      <th>HH_L5_magnitude</th>\n",
       "      <th>HH_L5_covariance</th>\n",
       "      <th>HH_L5_pcc</th>\n",
       "      <th>HH_L3_weight</th>\n",
       "      <th>HH_L3_magnitude</th>\n",
       "      <th>HH_L3_covariance</th>\n",
       "      <th>HH_L3_pcc</th>\n",
       "      <th>HH_L1_magnitude</th>\n",
       "      <th>HH_L1_radius</th>\n",
       "      <th>HH_L0_1_weight</th>\n",
       "      <th>HH_L0_1_magnitude</th>\n",
       "      <th>HH_L0_01_mean</th>\n",
       "      <th>HH_L0_01_std</th>\n",
       "      <th>HH_L0_01_magnitude</th>\n",
       "      <th>HH_L0_01_radius</th>\n",
       "      <th>HH_jit_L5_mean</th>\n",
       "      <th>HH_jit_L5_variance</th>\n",
       "      <th>HH_jit_L3_mean</th>\n",
       "      <th>HH_jit_L1_variance</th>\n",
       "      <th>HH_jit_L0_1_weight</th>\n",
       "      <th>HH_jit_L0_1_mean</th>\n",
       "      <th>HH_jit_L0_01_mean</th>\n",
       "      <th>HpHp_L5_radius</th>\n",
       "      <th>HpHp_L5_covariance</th>\n",
       "      <th>HpHp_L5_pcc</th>\n",
       "      <th>HpHp_L3_magnitude</th>\n",
       "      <th>HpHp_L3_covariance</th>\n",
       "      <th>HpHp_L1_mean</th>\n",
       "      <th>HpHp_L1_std</th>\n",
       "      <th>HpHp_L1_covariance</th>\n",
       "      <th>HpHp_L0_1_std</th>\n",
       "      <th>HpHp_L0_1_radius</th>\n",
       "      <th>HpHp_L0_1_pcc</th>\n",
       "      <th>HpHp_L0_01_weight</th>\n",
       "      <th>HpHp_L0_01_std</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136.671365</td>\n",
       "      <td>59723.823548</td>\n",
       "      <td>340.812082</td>\n",
       "      <td>59840.036542</td>\n",
       "      <td>32772.131597</td>\n",
       "      <td>341.840263</td>\n",
       "      <td>91.211324</td>\n",
       "      <td>56329.158936</td>\n",
       "      <td>136.671365</td>\n",
       "      <td>271.592486</td>\n",
       "      <td>59723.823548</td>\n",
       "      <td>384.092631</td>\n",
       "      <td>60853.558076</td>\n",
       "      <td>3855.164044</td>\n",
       "      <td>59840.036542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173.128639</td>\n",
       "      <td>34137.160623</td>\n",
       "      <td>390.985044</td>\n",
       "      <td>57924.428871</td>\n",
       "      <td>51189.559431</td>\n",
       "      <td>391.294253</td>\n",
       "      <td>95.029757</td>\n",
       "      <td>16807.590281</td>\n",
       "      <td>173.128639</td>\n",
       "      <td>485.834404</td>\n",
       "      <td>34137.160623</td>\n",
       "      <td>578.800756</td>\n",
       "      <td>53062.651631</td>\n",
       "      <td>6183.451303</td>\n",
       "      <td>57924.428871</td>\n",
       "      <td>88.317358</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.699788</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>5.238689e-10</td>\n",
       "      <td>4044.703405</td>\n",
       "      <td>565.993158</td>\n",
       "      <td>565.968119</td>\n",
       "      <td>4.016312</td>\n",
       "      <td>565.968119</td>\n",
       "      <td>16.130762</td>\n",
       "      <td>3.376842e-03</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>3.379372e-03</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>4044.703405</td>\n",
       "      <td>2.474174e-02</td>\n",
       "      <td>8.481503e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.853763</td>\n",
       "      <td>4.072216</td>\n",
       "      <td>60.097664</td>\n",
       "      <td>1.736939</td>\n",
       "      <td>19790.553326</td>\n",
       "      <td>60.096115</td>\n",
       "      <td>51.828167</td>\n",
       "      <td>3.639609</td>\n",
       "      <td>69.853763</td>\n",
       "      <td>60.178884</td>\n",
       "      <td>4.072216</td>\n",
       "      <td>196.266931</td>\n",
       "      <td>2.612387</td>\n",
       "      <td>2007.014853</td>\n",
       "      <td>1.736939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>1.507654e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136.713851</td>\n",
       "      <td>44912.104234</td>\n",
       "      <td>337.821252</td>\n",
       "      <td>60036.726634</td>\n",
       "      <td>10593.159382</td>\n",
       "      <td>344.609258</td>\n",
       "      <td>102.036581</td>\n",
       "      <td>36930.765509</td>\n",
       "      <td>136.713851</td>\n",
       "      <td>180.251616</td>\n",
       "      <td>44912.104234</td>\n",
       "      <td>338.369210</td>\n",
       "      <td>59860.066216</td>\n",
       "      <td>3680.360996</td>\n",
       "      <td>60036.726634</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>1.507656e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145.933664</td>\n",
       "      <td>56141.162620</td>\n",
       "      <td>336.375771</td>\n",
       "      <td>60140.845251</td>\n",
       "      <td>41710.317979</td>\n",
       "      <td>336.277714</td>\n",
       "      <td>78.185559</td>\n",
       "      <td>48184.566169</td>\n",
       "      <td>145.933664</td>\n",
       "      <td>376.769870</td>\n",
       "      <td>56141.162620</td>\n",
       "      <td>484.620543</td>\n",
       "      <td>59534.882875</td>\n",
       "      <td>5000.404592</td>\n",
       "      <td>60140.845251</td>\n",
       "      <td>57.016109</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.577706</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>2.369052e-07</td>\n",
       "      <td>2797.552202</td>\n",
       "      <td>553.979500</td>\n",
       "      <td>553.941593</td>\n",
       "      <td>5.371200</td>\n",
       "      <td>553.941593</td>\n",
       "      <td>28.849789</td>\n",
       "      <td>5.296807e-03</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>5.324834e-03</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>2797.552202</td>\n",
       "      <td>1.618776e-02</td>\n",
       "      <td>1.100238e+04</td>\n",
       "      <td>2.910383e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.402843e-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23326.393833</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MI_dir_L3_weight  MI_dir_L3_variance  MI_dir_L0_1_mean  MI_dir_L0_1_variance  MI_dir_L0_01_weight  MI_dir_L0_01_mean  H_L5_weight  H_L5_variance  H_L3_weight   H_L3_mean  H_L3_variance  H_L1_weight  H_L1_variance  H_L0_1_weight  H_L0_1_variance  HH_L5_weight  HH_L5_std  HH_L5_magnitude  HH_L5_covariance  HH_L5_pcc  HH_L3_weight  HH_L3_magnitude  HH_L3_covariance  HH_L3_pcc  HH_L1_magnitude  HH_L1_radius  HH_L0_1_weight  HH_L0_1_magnitude  HH_L0_01_mean  HH_L0_01_std  HH_L0_01_magnitude  HH_L0_01_radius  HH_jit_L5_mean  HH_jit_L5_variance  HH_jit_L3_mean  HH_jit_L1_variance  HH_jit_L0_1_weight  HH_jit_L0_1_mean  HH_jit_L0_01_mean  HpHp_L5_radius  HpHp_L5_covariance  HpHp_L5_pcc  HpHp_L3_magnitude  HpHp_L3_covariance  HpHp_L1_mean  HpHp_L1_std  HpHp_L1_covariance  HpHp_L0_1_std  HpHp_L0_1_radius  HpHp_L0_1_pcc  HpHp_L0_01_weight  HpHp_L0_01_std  label\n",
       "0        136.671365        59723.823548        340.812082          59840.036542         32772.131597         341.840263    91.211324   56329.158936   136.671365  271.592486   59723.823548   384.092631   60853.558076    3855.164044     59840.036542      1.000000   0.000000             60.0               0.0        0.0      1.000000             60.0               0.0        0.0             60.0  0.000000e+00        1.000000          60.000000      60.000000      0.000000           60.000000         0.000000    1.507656e+09            0.000000    1.507656e+09            0.000000            1.000000      1.507656e+09       1.507656e+09    0.000000e+00                 0.0          0.0               60.0                 0.0          60.0     0.000000                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "1        173.128639        34137.160623        390.985044          57924.428871         51189.559431         391.294253    95.029757   16807.590281   173.128639  485.834404   34137.160623   578.800756   53062.651631    6183.451303     57924.428871     88.317358   0.000013            566.0               0.0        0.0    145.699788            566.0               0.0        0.0            566.0  5.238689e-10     4044.703405         565.993158     565.968119      4.016312          565.968119        16.130762    3.376842e-03            0.000055    3.379372e-03            0.000117         4044.703405      2.474174e-02       8.481503e+03    0.000000e+00                 0.0          0.0              566.0                 0.0         566.0     0.000000                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "2         69.853763            4.072216         60.097664              1.736939         19790.553326          60.096115    51.828167       3.639609    69.853763   60.178884       4.072216   196.266931       2.612387    2007.014853         1.736939      1.000000   0.000000             60.0               0.0        0.0      1.000000             60.0               0.0        0.0             60.0  0.000000e+00        1.000000          60.000000      60.000000      0.000000           60.000000         0.000000    1.507654e+09            0.000000    1.507654e+09            0.000000            1.000000      1.507654e+09       1.507654e+09    0.000000e+00                 0.0          0.0               60.0                 0.0          60.0     0.000000                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "3        136.713851        44912.104234        337.821252          60036.726634         10593.159382         344.609258   102.036581   36930.765509   136.713851  180.251616   44912.104234   338.369210   59860.066216    3680.360996     60036.726634      1.000000   0.000000             60.0               0.0        0.0      1.000000             60.0               0.0        0.0             60.0  0.000000e+00        1.000000          60.000000      60.000000      0.000000           60.000000         0.000000    1.507656e+09            0.000000    1.507656e+09            0.000000            1.000000      1.507656e+09       1.507656e+09    0.000000e+00                 0.0          0.0               60.0                 0.0          60.0     0.000000                 0.0       0.000000      0.000000e+00            0.0           1.000000        0.000000      0\n",
       "4        145.933664        56141.162620        336.375771          60140.845251         41710.317979         336.277714    78.185559   48184.566169   145.933664  376.769870   56141.162620   484.620543   59534.882875    5000.404592     60140.845251     57.016109   0.000017            554.0               0.0        0.0     93.577706            554.0               0.0        0.0            554.0  2.369052e-07     2797.552202         553.979500     553.941593      5.371200          553.941593        28.849789    5.296807e-03            0.000134    5.324834e-03            0.000186         2797.552202      1.618776e-02       1.100238e+04    2.910383e-10                 0.0          0.0              554.0                 0.0         554.0     0.000015                 0.0       0.000025      6.402843e-10            0.0       23326.393833        0.000046      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = ps.read_csv('../../../../../datasets/dacoga/nbaiot/test/dsetN-Baiot_v2_100_test.csv')\n",
    "dfTest = dfTest[dfTrain.columns]\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando as colunas\n",
    "#dfTrain.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfTest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start algorithms time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeTrain = dfTrain.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=dataframeTrain.columns[:-1], outputCol='features')\n",
    "\n",
    "dsetTrain = vecAssembler.transform(dataframeTrain)\n",
    "dsetTrain = dsetTrain.select(\"label\",\"features\")\n",
    "\n",
    "#dfTrain.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mmScaler = feature.MinMaxScaler(inputCol='features', \n",
    "                                outputCol='scaled_features').fit(dsetTrain)\n",
    "\n",
    "dsetTrain = mmScaler.transform(dsetTrain).drop('features')\n",
    "dsetTrain = dsetTrain.withColumnRenamed('scaled_features', 'features')\n",
    "\n",
    "#dfTrain.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframeTest = dfTest.to_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=dataframeTest.columns[:-1], outputCol='features')\n",
    "\n",
    "dsetTest = vecAssembler.transform(dataframeTest)\n",
    "dsetTest = dsetTest.select(\"label\",\"features\")\n",
    "\n",
    "#dfTrain.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mmScaler = feature.MinMaxScaler(inputCol='features', \n",
    "                                outputCol='scaled_features').fit(dsetTest)\n",
    "\n",
    "dsetTest = mmScaler.transform(dsetTest).drop('features')\n",
    "dsetTest = dsetTest.withColumnRenamed('scaled_features', 'features')\n",
    "\n",
    "#dfTrain.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split ramdomly the dataset into train and test group\n",
    "# [0.7,0.3] => 70% for train and 30% for test\n",
    "# [1.0,0.2] => 100% for train and 20% for test, not good, acuracy always 100%\n",
    "# [0.1,0.02] => 10% for train and 2% for test, if big datasets\n",
    "# 1234 is the random seed\n",
    "\n",
    "# Sample of train and test dataset\n",
    "train_sample = 0.7\n",
    "test_sample = 0.3\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#(trainingData, testData) = df_spark.randomSplit([train_sample, test_sample], seed=1234)\n",
    "\n",
    "trainingData = dsetTrain\n",
    "testData = dsetTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário de resultados\n",
    "dic = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando com Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time_dt =  time.time()\n",
    "\n",
    "# Train a DecisionTree model\n",
    "clf_dt = DecisionTreeClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability', \\\n",
    "                            rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0, \\\n",
    "                            maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', seed=None)\n",
    "\n",
    "# Train model\n",
    "model_dt = clf_dt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "pred_dt = model_dt.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:==========================================>             (18 + 6) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "========== Sumário da Avaliação Árvore de Decisão ==========\n",
      "Acurácia = 99.72 %\n",
      "Precisão = 99.66 %\n",
      "Recall = 99.99 %\n",
      "F1-Score = 99.72 %\n",
      "Curva ROC = 99.72 %\n",
      "Tempo de Execução = 105.853 s\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on the test set against model and select (prediction, true label) and compute test error\n",
    "eval_accuracy_dt = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "eval_precision_dt = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "eval_recall_dt = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "eval_f1_dt = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "eval_auc_dt = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "\n",
    "accuracy_dt = eval_accuracy_dt.evaluate(pred_dt) * 100\n",
    "precision_dt = eval_precision_dt.evaluate(pred_dt) * 100\n",
    "recall_dt = eval_recall_dt.evaluate(pred_dt) * 100\n",
    "f1score_dt = eval_f1_dt.evaluate(pred_dt) * 100\n",
    "auc_dt = eval_accuracy_dt.evaluate(pred_dt) * 100\n",
    "\n",
    "dic['Árvore de\\nDecisão']  = accuracy_dt\n",
    "time_dt = time.time() - start_time_dt\n",
    "\n",
    "print(\"============================================================\")\n",
    "print(\"========== Sumário da Avaliação Árvore de Decisão ==========\")\n",
    "print(\"Acurácia = %3.2f %%\" % accuracy_dt)\n",
    "print(\"Precisão = %3.2f %%\" % precision_dt)\n",
    "print(\"Recall = %3.2f %%\" % recall_dt)\n",
    "print(\"F1-Score = %3.2f %%\" % f1score_dt)\n",
    "print(\"Curva ROC = %3.2f %%\" % auc_dt)\n",
    "print(\"Tempo de Execução = %3.3f s\" % time_dt)\n",
    "print(\"============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|    1|       1.0|152026|\n",
      "|    0|       0.0|590051|\n",
      "|    0|       1.0|    31|\n",
      "|    1|       0.0|  2039|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=====================================================>  (23 + 1) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|label|     0|     1|\n",
      "+-----+------+------+\n",
      "|    1|  2039|152026|\n",
      "|    0|590051|    31|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Agrupar por rótulos reais e previsões e contar o número de ocorrências\n",
    "confusion_matrix_df = pred_dt.groupBy('label', 'prediction').count()\n",
    "\n",
    "# Para visualizar a matriz de confusão como um DataFrame\n",
    "confusion_matrix_df.show()\n",
    "\n",
    "# Para uma melhor visualização e entendimento, você pode pivotar os dados\n",
    "# Isso é útil especialmente se você tem um número fixo de classes e deseja uma matriz quadrada\n",
    "confusion_matrix_pivot_dt = confusion_matrix_df.groupBy('label').pivot('prediction', [0, 1]).sum('count')\\\n",
    "                                            .fillna(0) # substitui os NAs por 0 para casos onde não há previsões para uma classe\n",
    "\n",
    "confusion_matrix_pivot_dt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Decision Tree Final Result\")\n",
    "# predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando com Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time_rf =  time.time()\n",
    "\n",
    "# Train a Random Forest model\n",
    "clf_rf = RandomForestClassifier(featuresCol='features', labelCol='label', predictionCol='prediction', probabilityCol='probability',\\\n",
    "                                 rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0,\\\n",
    "                                 numTrees=50, featureSubsetStrategy='auto', seed=None, subsamplingRate=1.0,\\\n",
    "                                 maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini')\n",
    "\n",
    "# Train model\n",
    "model_rf = clf_rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "pred_rf = model_rf.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:=================================================>      (21 + 3) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "========== Sumário da Avaliação Random Forest ==========\n",
      "Acurácia = 99.98 %\n",
      "Precisão = 100.00 %\n",
      "Recall = 99.98 %\n",
      "F1-Score = 99.98 %\n",
      "Curva ROC = 99.98 %\n",
      "Tempo de Execução = 71.404 s\n",
      "========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on the test set against model and select (prediction, true label) and compute test error\n",
    "eval_accuracy_rf = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "eval_precision_rf = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "eval_recall_rf = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "eval_f1_rf = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "eval_auc_rf = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "\n",
    "accuracy_rf = eval_accuracy_dt.evaluate(pred_rf) * 100\n",
    "precision_rf = eval_precision_dt.evaluate(pred_rf) * 100\n",
    "recall_rf = eval_recall_dt.evaluate(pred_rf) * 100\n",
    "f1score_rf = eval_f1_dt.evaluate(pred_rf) * 100\n",
    "auc_rf = eval_accuracy_dt.evaluate(pred_rf) * 100\n",
    "\n",
    "dic['Random\\nForest']  = accuracy_rf\n",
    "time_rf = time.time() - start_time_rf\n",
    "\n",
    "print(\"========================================================\")\n",
    "print(\"========== Sumário da Avaliação Random Forest ==========\")\n",
    "print(\"Acurácia = %3.2f %%\" % accuracy_rf)\n",
    "print(\"Precisão = %3.2f %%\" % precision_rf)\n",
    "print(\"Recall = %3.2f %%\" % recall_rf)\n",
    "print(\"F1-Score = %3.2f %%\" % f1score_rf)\n",
    "print(\"Curva ROC = %3.2f %%\" % auc_rf)\n",
    "print(\"Tempo de Execução = %3.3f s\" % time_rf)\n",
    "print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|    1|       1.0|154047|\n",
      "|    0|       0.0|589959|\n",
      "|    0|       1.0|   123|\n",
      "|    1|       0.0|    18|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:===================================>                    (15 + 9) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|label|     0|     1|\n",
      "+-----+------+------+\n",
      "|    1|    18|154047|\n",
      "|    0|589959|   123|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Agrupar por rótulos reais e previsões e contar o número de ocorrências\n",
    "confusion_matrix_rf = pred_rf.groupBy('label', 'prediction').count()\n",
    "\n",
    "# Para visualizar a matriz de confusão como um DataFrame\n",
    "confusion_matrix_rf.show()\n",
    "\n",
    "# Para uma melhor visualização e entendimento, você pode pivotar os dados\n",
    "# Isso é útil especialmente se você tem um número fixo de classes e deseja uma matriz quadrada\n",
    "confusion_matrix_pivot_rf = confusion_matrix_rf.groupBy('label').pivot('prediction', [0, 1]).sum('count')\\\n",
    "                                            .fillna(0) # substitui os NAs por 0 para casos onde não há previsões para uma classe\n",
    "\n",
    "confusion_matrix_pivot_rf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando com Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time_nb =  time.time()\n",
    "\n",
    "clf_nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# Train model\n",
    "model_nb = clf_nb.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "pred_nb = model_nb.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 97:==============================================>         (20 + 4) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================\n",
      "========== Sumário da Avaliação Naive Bayes ==========\n",
      "Acurácia = 99.89 %\n",
      "Precisão = 99.90 %\n",
      "Recall = 99.96 %\n",
      "F1-Score = 99.89 %\n",
      "Curva ROC = 99.89 %\n",
      "Tempo de Execução = 234.105 s\n",
      "======================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on the test set against model and select (prediction, true label) and compute test error\n",
    "eval_accuracy_nb = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "eval_precision_nb = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "eval_recall_nb = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "eval_f1_nb = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "eval_auc_nb = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "\n",
    "accuracy_nb = eval_accuracy_dt.evaluate(pred_nb) * 100\n",
    "precision_nb = eval_precision_dt.evaluate(pred_nb) * 100\n",
    "recall_nb = eval_recall_dt.evaluate(pred_nb) * 100\n",
    "f1score_nb = eval_f1_dt.evaluate(pred_nb) * 100\n",
    "auc_nb = eval_accuracy_dt.evaluate(pred_nb) * 100\n",
    "\n",
    "dic[\"Naive\\nBayes\"]  = accuracy_nb\n",
    "time_nb = time.time() - start_time_nb\n",
    "\n",
    "print(\"======================================================\")\n",
    "print(\"========== Sumário da Avaliação Naive Bayes ==========\")\n",
    "print(\"Acurácia = %3.2f %%\" % accuracy_nb)\n",
    "print(\"Precisão = %3.2f %%\" % precision_nb)\n",
    "print(\"Recall = %3.2f %%\" % recall_nb)\n",
    "print(\"F1-Score = %3.2f %%\" % f1score_nb)\n",
    "print(\"Curva ROC = %3.2f %%\" % auc_nb)\n",
    "print(\"Tempo de Execução = %3.3f s\" % time_nb)\n",
    "print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|    1|       1.0|153479|\n",
      "|    0|       0.0|589864|\n",
      "|    0|       1.0|   218|\n",
      "|    1|       0.0|   586|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:==================================>                    (15 + 9) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|label|     0|     1|\n",
      "+-----+------+------+\n",
      "|    1|    18|154047|\n",
      "|    0|589959|   123|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Agrupar por rótulos reais e previsões e contar o número de ocorrências\n",
    "confusion_matrix_nb = pred_nb.groupBy('label', 'prediction').count()\n",
    "\n",
    "# Para visualizar a matriz de confusão como um DataFrame\n",
    "confusion_matrix_nb.show()\n",
    "\n",
    "# Para uma melhor visualização e entendimento, você pode pivotar os dados\n",
    "# Isso é útil especialmente se você tem um número fixo de classes e deseja uma matriz quadrada\n",
    "confusion_matrix_pivot_nb = confusion_matrix_rf.groupBy('label').pivot('prediction', [0, 1]).sum('count')\\\n",
    "                                            .fillna(0) # substitui os NAs por 0 para casos onde não há previsões para uma classe\n",
    "\n",
    "confusion_matrix_pivot_nb.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando e avaliando com Suport Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/25 15:24:26 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time_svm =  time.time()\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "clf_svm = LinearSVC(featuresCol='features', labelCol='label', maxIter=10, regParam=0.1)\n",
    "\n",
    "# train the multiclass model.\n",
    "model_svm = clf_svm.fit(trainingData)\n",
    "\n",
    "# score the model on test data.\n",
    "pred_svm = model_svm.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 170:==================================================>    (22 + 2) / 24]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "========== Sumário da Avaliação SVM ==========\n",
      "Acurácia = 96.61 %\n",
      "Precisão = 95.91 %\n",
      "Recall = 99.99 %\n",
      "F1-Score = 96.50 %\n",
      "Curva ROC = 96.61 %\n",
      "Tempo de Execução = 2800.548 s\n",
      "==============================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on the test set against model and select (prediction, true label) and compute test error\n",
    "eval_accuracy_svm = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "eval_precision_svm = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "eval_recall_svm = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "eval_f1_svm = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "eval_auc_svm = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\")\n",
    "\n",
    "accuracy_svm = eval_accuracy_svm.evaluate(pred_svm) * 100\n",
    "precision_svm = eval_precision_svm.evaluate(pred_svm) * 100\n",
    "recall_svm = eval_recall_svm.evaluate(pred_svm) * 100\n",
    "f1score_svm = eval_f1_svm.evaluate(pred_svm) * 100\n",
    "auc_svm = eval_accuracy_svm.evaluate(pred_svm) * 100\n",
    "\n",
    "dic[\"SVM\"]  = accuracy_svm\n",
    "time_svm = time.time() - start_time_svm\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(\"========== Sumário da Avaliação SVM ==========\")\n",
    "print(\"Acurácia = %3.2f %%\" % accuracy_svm)\n",
    "print(\"Precisão = %3.2f %%\" % precision_svm)\n",
    "print(\"Recall = %3.2f %%\" % recall_svm)\n",
    "print(\"F1-Score = %3.2f %%\" % f1score_svm)\n",
    "print(\"Curva ROC = %3.2f %%\" % auc_svm)\n",
    "print(\"Tempo de Execução = %3.3f s\" % time_svm)\n",
    "print(\"==============================================\")\n",
    "# https://www.kaggle.com/code/shrutimechlearn/pyspark-part-3-classification-modelling-dtree\n",
    "# https://spark.apache.org/docs/latest/ml-classification-regression.html#linear-support-vector-machine\n",
    "# https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "=========================  Compare Algorithm and Time ==========================\n",
      "\n",
      "Técnicas               Acurácia  Precisão  Recall   F1-Score   ROC      Tempo\n",
      "Decision Tree:         99.722%   99.656%   99.995%  99.721%    99.722%  105.853s\n",
      "Random Forest:         99.981%   99.997%   99.979%  99.981%    99.981%  71.404s\n",
      "Naive Bayes:           99.892%   99.901%   99.963%  99.892%    99.892%  234.105s\n",
      "SVM:                   96.610%   95.911%   99.988%  96.495%    96.610%  2800.548s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"================================================================================\")\n",
    "print(\"=========================  Compare Algorithm and Time ==========================\")\n",
    "print()\n",
    "print(\"Técnicas               Acurácia  Precisão  Recall   F1-Score   ROC      Tempo\")\n",
    "print(\"Decision Tree:         %3.3f%%   %3.3f%%   %3.3f%%  %3.3f%%    %3.3f%%  %3.3fs\" % (accuracy_dt, precision_dt, recall_dt, f1score_dt, auc_dt, time_dt))\n",
    "print(\"Random Forest:         %3.3f%%   %3.3f%%   %3.3f%%  %3.3f%%    %3.3f%%  %3.3fs\" % (accuracy_rf, precision_rf, recall_rf, f1score_rf, auc_rf, time_rf))\n",
    "print(\"Naive Bayes:           %3.3f%%   %3.3f%%   %3.3f%%  %3.3f%%    %3.3f%%  %3.3fs\" % (accuracy_nb, precision_nb, recall_nb, f1score_nb, auc_nb, time_nb))\n",
    "print(\"SVM:                   %3.3f%%   %3.3f%%   %3.3f%%  %3.3f%%    %3.3f%%  %3.3fs\" % (accuracy_svm,precision_svm,recall_svm,f1score_svm,auc_svm,time_svm))\n",
    "print(\"================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Árvore de\\nDecisão    99.721829\n",
       "Random\\nForest        99.981052\n",
       "Naive\\nBayes          99.891957\n",
       "SVM                   96.610213\n",
       "Name: Acurácia, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = pd.Series(dic, name=\"Acurácia\")\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '99.7218'),\n",
       " Text(0, 0, '99.9811'),\n",
       " Text(0, 0, '99.8920'),\n",
       " Text(0, 0, '96.6102')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classificadores = dic.keys()\n",
    "acc = dic.values()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_container = ax.bar(classificadores, acc)\n",
    "#ax.set(ylabel='Acurácia', xlabel='Classificadores', title='Acurácia dos Classificadores', ylim=(0, 1.1))\n",
    "ax.set(ylabel='Acurácia', xlabel='Classificadores', title='Acurácia dos Classificadores')\n",
    "ax.bar_label(bar_container, fmt='{:,.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tempo de execução: 3307.21 segundos ---\n"
     ]
    }
   ],
   "source": [
    "# Contabiliza o tempo de execução do algoritmo\n",
    "tempo_total = (time.time() - start_time)\n",
    "print(f'--- Tempo de execução: {tempo_total:.2f} segundos ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "30X40_ABAOCPMeasure-SVM-wine.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
